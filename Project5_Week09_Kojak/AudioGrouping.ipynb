{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Kojak - Weeks 09 - 12\n",
    "\n",
    "## Defining groups of speakers for training and testing\n",
    "(Jupyter Notebook 2 of 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook.\n",
    "\n",
    "This notebook focuses on making random groupings of the various speakers in the TIMIT corpus. The TIMIT corpus has two subdivisions of data called TRAIN and TEST. I used the TRAIN data to create the 100 \"household\" groups of 6 people each, though this data set also has a training subset (7 sentences of the 10 spoken) and test subset (3 sentences). I reserved the TEST data to create groups of unfamiliar (out-of-group) speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, set the groundwork for creating the 100 speaker groups ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the distribution of speakers in terms of gender and #\n",
    "# dialect region of the U.S., for every \"household\" smart speaker. #\n",
    "# Dictionary format is (# males, # females, # regions) : repetitions.\n",
    "SPKR_CNT = 6\n",
    "nrepeat = 10\n",
    "batch_distr = {(3,3,1):nrepeat, (3,3,3):nrepeat, (3,3,7):nrepeat,\n",
    "               (0,6,1):nrepeat, (0,6,3):nrepeat, (0,6,7):nrepeat,\n",
    "               (6,0,1):nrepeat, (6,0,3):nrepeat, (6,0,7):nrepeat,\n",
    "               (3,3,'dr8'):2, (0,6,'dr8'):4, (6,0,'dr8'):4\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function creates random groups of speakers following certain rules. #\n",
    "# Total # of male and female in input arguments must equal the length\n",
    "# of 'dr_list', the dialect regions from which the speakers are to be\n",
    "# chosen. The region list should already be randomized (if desired),\n",
    "# as the gender list will not be (males precede females).\n",
    "def get_speakers(nmales, nfemales, nreg, dr_list, wavbase='data/TRAIN'):\n",
    "    g_list = ['m']*nmales + ['f']*nfemales\n",
    "    if len(g_list) != len(dr_list):\n",
    "        raise ValueError('M/F and region lists do not have equal lengths.')\n",
    "    \n",
    "    cwd = os.getcwd()   # store current directory\n",
    "    \n",
    "    spkr_list = []      # temporarily change to region directory\n",
    "    for i in range(len(dr_list)):\n",
    "        dr_next = dr_list[i].upper()\n",
    "        g_next = g_list[i].upper() # g = gender = \"M\" or \"F\"\n",
    "        os.chdir('/'.join([cwd,wavbase,dr_next]))\n",
    "                        # randomly pick speaker from directory\n",
    "        spkr_matches = glob.glob(g_next + '*')\n",
    "        idx = np.random.randint(len(spkr_matches))\n",
    "        spkr = spkr_matches[idx]\n",
    "        while spkr in spkr_list:   # repeat if speaker already in group\n",
    "            idx = np.random.randint(len(spkr_matches))\n",
    "            spkr = spkr_matches[idx]\n",
    "        spkr_list.append(spkr)\n",
    "        \n",
    "    os.chdir(cwd)      # at end, revert back to original directory\n",
    "    \n",
    "    return spkr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get audio files from TIMIT database, given dialect region + speaker #\n",
    "# Argument 'split' gives the percentage of files (of 10) to use in the\n",
    "# training set; this must be at least 0.8; the rest go to the test set.\n",
    "# The train/test allocation is semi-random and executed using indexes\n",
    "# into the list of file names rather than the file names themselves.\n",
    "def get_audiofiles(dr, spkr, split=0.7, wavbase='data/TRAIN'):\n",
    "    wavdir = '/'.join([wavbase,dr,spkr]).upper()\n",
    "    wavlist = glob.glob(wavdir + '/*.WAV')\n",
    "    nwav = len(wavlist)\n",
    "    \n",
    "    train_idx, test_idx = [], []\n",
    "    all_idx = range(nwav)\n",
    "    \n",
    "    # At least one 'SA' and one 'SI' file must be in the test set #\n",
    "    sa_idx = [bool(glob.re.search('/SA',wav)) for wav in wavlist]\n",
    "    sa_idx = np.random.permutation(list(compress(all_idx,sa_idx)))\n",
    "    si_idx = [bool(glob.re.search('/SI',wav)) for wav in wavlist]\n",
    "    si_idx = np.random.permutation(list(compress(all_idx,si_idx)))\n",
    "    \n",
    "    test_idx.append(sa_idx[0])\n",
    "    test_idx.append(si_idx[0])\n",
    "    \n",
    "    # And at least one 'SA' in the training set #\n",
    "    train_idx.append(sa_idx[1])\n",
    "    \n",
    "    # All others distribute to achieve the train/test split ratio #\n",
    "    unused_idx = [i for i in all_idx if not (i in test_idx or i in train_idx)]\n",
    "    unused_idx = np.random.permutation(unused_idx)\n",
    "    ntest = int(max(np.floor(nwav*(1.-split)) - len(test_idx), 0))\n",
    "    \n",
    "    if ntest:  # 'ntest' = additional # wav files to allocate to test set\n",
    "        test_idx.extend(unused_idx[:ntest])\n",
    "    train_idx.extend(unused_idx[ntest:])\n",
    "    \n",
    "    # Finally, assign wav files based on indexes into the list #\n",
    "    train_wavlist = list(np.array(wavlist)[train_idx])\n",
    "    test_wavlist = list(np.array(wavlist)[test_idx])\n",
    "\n",
    "    return train_wavlist, test_wavlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the speaker groups ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through intructions in 'batch_distr' to get random speakers #\n",
    "# Save the names of the speakers and regions, the .wav file names, and\n",
    "# other info. Define the distribution of speakers in terms of gender and\n",
    "# dialect region of the U.S., for every \"household\" smart speaker.\n",
    "# Dictionary format is (# males, # females, # regions) : repetitions.\n",
    "SPKR_CNT = 6\n",
    "REGION_NAMES = ('dr1','dr2','dr3','dr4','dr5','dr6','dr7')\n",
    "nrepeat = 10\n",
    "batch_distr = {(3,3,1):nrepeat, (3,3,3):nrepeat, (3,3,7):nrepeat,\n",
    "               (0,6,1):nrepeat, (0,6,3):nrepeat, (0,6,7):nrepeat,\n",
    "               (6,0,1):nrepeat, (6,0,3):nrepeat, (6,0,7):nrepeat,\n",
    "               (3,3,'dr8'):2, (0,6,'dr8'):4, (6,0,'dr8'):4\n",
    "              }\n",
    "\n",
    "batch_info = {}\n",
    "cnt = 0\n",
    "for code in batch_distr:\n",
    "    for i in range(batch_distr[code]):\n",
    "        cnt += 1\n",
    "        if type(code[2]) is str:   # for specific region, just repeat it\n",
    "            region_list = [code[2]]*SPKR_CNT\n",
    "        else:   # otherwise, create random lists of size SPKR_CNT\n",
    "            region_subset = np.random.permutation(REGION_NAMES)\n",
    "            region_subset = region_subset[0:code[2]]\n",
    "            idx = np.random.randint(0, len(region_subset), SPKR_CNT)\n",
    "            region_list = [region_subset[i] for i in idx]\n",
    "        \n",
    "        speaker_list = get_speakers(*code, region_list,\n",
    "                                    wavbase='data/TRAIN')\n",
    "        train_files, test_files = [], []\n",
    "        for j in range(len(speaker_list)):\n",
    "            reg = region_list[j]\n",
    "            spk = speaker_list[j]\n",
    "            train, test = get_audiofiles(reg, spk,\n",
    "                                         split=0.7, wavbase='data/TRAIN')\n",
    "            train_files.append(train)\n",
    "            test_files.append(test)\n",
    "\n",
    "        nregion = len(np.unique(region_list))\n",
    "        diversity = 10 - (abs(code[1]-code[0]) + 0.1*(6-nregion))\n",
    "\n",
    "        batch_info[cnt] = {'device':cnt, 'code':code,\n",
    "            'regions':region_list, 'speakers':speaker_list,\n",
    "            'train':train_files, 'test':test_files,\n",
    "            'nregion':nregion, 'diversity':diversity\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 22,\n",
       " 'code': (3, 3, 7),\n",
       " 'regions': ['dr1', 'dr6', 'dr2', 'dr5', 'dr2', 'dr5'],\n",
       " 'speakers': ['MDAC0', 'MKLN0', 'MEFG0', 'FBJL0', 'FSKL0', 'FLOD0'],\n",
       " 'train': [['DATA/TRAIN/DR1/MDAC0/SA1.WAV',\n",
       "   'DATA/TRAIN/DR1/MDAC0/SX451.WAV',\n",
       "   'DATA/TRAIN/DR1/MDAC0/SX181.WAV',\n",
       "   'DATA/TRAIN/DR1/MDAC0/SX91.WAV',\n",
       "   'DATA/TRAIN/DR1/MDAC0/SX361.WAV',\n",
       "   'DATA/TRAIN/DR1/MDAC0/SI1261.WAV',\n",
       "   'DATA/TRAIN/DR1/MDAC0/SX271.WAV'],\n",
       "  ['DATA/TRAIN/DR6/MKLN0/SA1.WAV',\n",
       "   'DATA/TRAIN/DR6/MKLN0/SX428.WAV',\n",
       "   'DATA/TRAIN/DR6/MKLN0/SX68.WAV',\n",
       "   'DATA/TRAIN/DR6/MKLN0/SI968.WAV',\n",
       "   'DATA/TRAIN/DR6/MKLN0/SX338.WAV',\n",
       "   'DATA/TRAIN/DR6/MKLN0/SX248.WAV',\n",
       "   'DATA/TRAIN/DR6/MKLN0/SI1598.WAV'],\n",
       "  ['DATA/TRAIN/DR2/MEFG0/SA1.WAV',\n",
       "   'DATA/TRAIN/DR2/MEFG0/SX375.WAV',\n",
       "   'DATA/TRAIN/DR2/MEFG0/SX285.WAV',\n",
       "   'DATA/TRAIN/DR2/MEFG0/SX105.WAV',\n",
       "   'DATA/TRAIN/DR2/MEFG0/SX15.WAV',\n",
       "   'DATA/TRAIN/DR2/MEFG0/SX195.WAV',\n",
       "   'DATA/TRAIN/DR2/MEFG0/SI598.WAV'],\n",
       "  ['DATA/TRAIN/DR5/FBJL0/SA1.WAV',\n",
       "   'DATA/TRAIN/DR5/FBJL0/SX202.WAV',\n",
       "   'DATA/TRAIN/DR5/FBJL0/SX112.WAV',\n",
       "   'DATA/TRAIN/DR5/FBJL0/SX382.WAV',\n",
       "   'DATA/TRAIN/DR5/FBJL0/SX292.WAV',\n",
       "   'DATA/TRAIN/DR5/FBJL0/SI922.WAV',\n",
       "   'DATA/TRAIN/DR5/FBJL0/SX22.WAV'],\n",
       "  ['DATA/TRAIN/DR2/FSKL0/SA2.WAV',\n",
       "   'DATA/TRAIN/DR2/FSKL0/SX359.WAV',\n",
       "   'DATA/TRAIN/DR2/FSKL0/SI2159.WAV',\n",
       "   'DATA/TRAIN/DR2/FSKL0/SX179.WAV',\n",
       "   'DATA/TRAIN/DR2/FSKL0/SX89.WAV',\n",
       "   'DATA/TRAIN/DR2/FSKL0/SX269.WAV',\n",
       "   'DATA/TRAIN/DR2/FSKL0/SX449.WAV'],\n",
       "  ['DATA/TRAIN/DR5/FLOD0/SA1.WAV',\n",
       "   'DATA/TRAIN/DR5/FLOD0/SX387.WAV',\n",
       "   'DATA/TRAIN/DR5/FLOD0/SX297.WAV',\n",
       "   'DATA/TRAIN/DR5/FLOD0/SI657.WAV',\n",
       "   'DATA/TRAIN/DR5/FLOD0/SX171.WAV',\n",
       "   'DATA/TRAIN/DR5/FLOD0/SX117.WAV',\n",
       "   'DATA/TRAIN/DR5/FLOD0/SX207.WAV']],\n",
       " 'test': [['DATA/TRAIN/DR1/MDAC0/SA2.WAV',\n",
       "   'DATA/TRAIN/DR1/MDAC0/SI1837.WAV',\n",
       "   'DATA/TRAIN/DR1/MDAC0/SI631.WAV'],\n",
       "  ['DATA/TRAIN/DR6/MKLN0/SA2.WAV',\n",
       "   'DATA/TRAIN/DR6/MKLN0/SI2228.WAV',\n",
       "   'DATA/TRAIN/DR6/MKLN0/SX158.WAV'],\n",
       "  ['DATA/TRAIN/DR2/MEFG0/SA2.WAV',\n",
       "   'DATA/TRAIN/DR2/MEFG0/SI465.WAV',\n",
       "   'DATA/TRAIN/DR2/MEFG0/SI491.WAV'],\n",
       "  ['DATA/TRAIN/DR5/FBJL0/SA2.WAV',\n",
       "   'DATA/TRAIN/DR5/FBJL0/SI1552.WAV',\n",
       "   'DATA/TRAIN/DR5/FBJL0/SI2182.WAV'],\n",
       "  ['DATA/TRAIN/DR2/FSKL0/SA1.WAV',\n",
       "   'DATA/TRAIN/DR2/FSKL0/SI1529.WAV',\n",
       "   'DATA/TRAIN/DR2/FSKL0/SI899.WAV'],\n",
       "  ['DATA/TRAIN/DR5/FLOD0/SA2.WAV',\n",
       "   'DATA/TRAIN/DR5/FLOD0/SI1287.WAV',\n",
       "   'DATA/TRAIN/DR5/FLOD0/SI1917.WAV']],\n",
       " 'nregion': 4,\n",
       " 'diversity': 9.8}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show an example of one group, or \"household\", of 6 members #\n",
    "batch_info[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the batch file #\n",
    "import pickle\n",
    "\n",
    "with open('data/batch_training02.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(batch_info, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a different batch set for speakers who aren't part of a group ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, just collect ALL of the speaker files in the \"TEST\" subdirectory #\n",
    "batch_info2 = []   # a list this time, rather than a dictionary\n",
    "subdir_list = glob.glob('data/TEST/*')\n",
    "\n",
    "for subdir in subdir_list:\n",
    "    wavlist = [wav for spkrdir in glob.glob(subdir+'/*')  \\\n",
    "               for wav in glob.glob(spkrdir+'/*.WAV')]\n",
    "    batch_info2.extend(wavlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/TEST/DR4/FADG0/SX289.WAV', 'data/TEST/DR4/FADG0/SX199.WAV']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a few file examples #\n",
    "batch_info2[101:103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the batch file #\n",
    "import pickle\n",
    "\n",
    "with open('data/batch_test02.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(batch_info2, picklefile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
