{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Natural Language Processing of Economic News Articles_\n",
    "## Post-Metis Analysis - Token Creation and Visualization\n",
    "\n",
    "(Jupyter Notebook 2 of ??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------ Section 2: Tokenize the cleaned articles -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from gensim import corpora\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# y_relevance = list(dfnews['relevance'])\n",
    "# y_positivity = list(dfnews['positivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define typical stop words plus those likely common to economic articles, without impacting positivity #\n",
    "# Note: I shouldn't remove these for bi-gram analysis.\n",
    "STOPWORDS_EXTRA = ['economic', 'finance', 'monetary', 'government', 'bank', 'money', 'amount', 'market']\n",
    "\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "for entry in STOPWORDS_EXTRA:    # could also use spacy's built-in stopword system\n",
    "    en_stop.add(entry)             # (e.g. nlp.vocab['market'].is_stop = True), except doesn't work for _md model\n",
    "    en_stop.add(entry+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up data version with common headers (e.g. \"NEW YORK --\") removed in NewsClassifier_RemoveHeaders.ipynb #\n",
    "import pickle\n",
    "\n",
    "with open('./saved_files/clean_NewsEcon2_a.pkl', 'rb') as picklefile: \n",
    "    clean_articles = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEPS\n",
    "-- remove stopwords  \n",
    "-- x_bow = bag of words  \n",
    "-- x_tfidf = tf-idf  \n",
    "-- Naive Bayes  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function adapted from original in NLP_Analysis.py #\n",
    "def tokenize(document, nlp, stopwords, stoppos = ['PROPN','DET','PUNCT','NUM','PRON','SYM'],\n",
    "             NER_tags = ['GRE','LOC','ORG','NORP','FAC','LANGUAGE','MONEY','LAW']):\n",
    "    \"\"\" Tokenize items in string 'document', suitable for news articles.\n",
    "        nlp: standard SpaCy object\n",
    "        stopwords, stoppos: list of words (before lemmatizing) and parts-of-speech to exclude\n",
    "    \"\"\"\n",
    "    doc_tokens = []\n",
    "    \n",
    "    # Analyze all words, rejecting unwanted parts of speech #\n",
    "    tokens = nlp(document)  # nlp() = standard SpaCy processing tool\n",
    "    for token in tokens:\n",
    "        if token.is_space or token.is_punct or token.like_url:\n",
    "            continue\n",
    "        if (token.text not in stopwords) and (token.pos_ not in stoppos):\n",
    "            lemma = token.lemma_     # note: this makes the word lower case\n",
    "            if lemma and lemma!='-PRON-':\n",
    "                doc_tokens.append(lemma)\n",
    "                \n",
    "    for entity in tokens.ents:\n",
    "        if entity.label_ in NER_tags: # first remove '99' (only nec. to assure NER worked)\n",
    "            ent_text = entity.text.upper()\n",
    "            ent_text = re.sub(r'([ ]*)99[ ]*', r'\\1', ent_text)\n",
    "            \n",
    "            if re.match(r'[a-zA-Z]', ent_text):  # reject orphaned entities\n",
    "                doc_tokens.append(ent_text + ' : ' + entity.label_)\n",
    "            \n",
    "            for ent_lemma in nlp(entity.text):\n",
    "                ent_lemma = ent_lemma.lemma_\n",
    "                if doc_tokens.count(ent_lemma):  # remove lemma version if present\n",
    "                    doc_tokens.remove(ent_lemma)\n",
    "\n",
    "    return doc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outlook',\n",
       " 'end',\n",
       " 'reading',\n",
       " 'third',\n",
       " 'contract',\n",
       " 'historical',\n",
       " 'minus',\n",
       " 'annualiz',\n",
       " 'would',\n",
       " 'gain',\n",
       " 'enough',\n",
       " 'order',\n",
       " 'G7 GROUP : ORG']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a few tokens in an example article #\n",
    "# Note the named entity \"G7 Group\" appears in all caps with a tag.\n",
    "tokens = tokenize(clean_articles[19], nlp, en_stop)\n",
    "tokens[::10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------ Section 3: Create a bag of words from the tokens -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def my_tokenizer(documents, my_nlp=nlp, my_stopwords=en_stop):\n",
    "#     func = tokenize(documents, nlp = my_nlp, stopwords = my_stopwords)\n",
    "    return tokenize(documents, nlp=my_nlp, stopwords=my_stopwords)\n",
    "\n",
    "cv_object = CountVectorizer(tokenizer=my_tokenizer, preprocessor=None, lowercase=False,\n",
    "                            analyzer='word')\n",
    "bow_array = cv_object.fit_transform(clean_articles[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_object.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABOVE CENTS : MONEY',\n",
       " 'AMERICANS : NORP',\n",
       " 'AP : ORG',\n",
       " 'AT LEAST $BILLION : MONEY',\n",
       " 'BANXQUOTE : ORG',\n",
       " 'BANXQUOTE MONEY MARKETS : ORG',\n",
       " 'CENT : MONEY',\n",
       " 'CENTS : MONEY',\n",
       " 'CITIBANK : ORG',\n",
       " 'CONGRESS : ORG',\n",
       " 'CORESTATES : ORG',\n",
       " 'D. : NORP',\n",
       " 'DEMOCRATS : NORP',\n",
       " 'EAP : ORG',\n",
       " 'FAMILIES USA : ORG',\n",
       " 'FRANCS : MONEY',\n",
       " 'HOUSE : ORG',\n",
       " 'JAPANESE : NORP',\n",
       " 'MEDICAID : ORG',\n",
       " 'REPUBLICANS : NORP',\n",
       " 'SCHIP : ORG',\n",
       " 'SENATE : ORG',\n",
       " 'SWISS : NORP',\n",
       " 'THE ASSOCIATED PRESS : ORG',\n",
       " 'THE CENTERS FOR DISEASE CONTROL : ORG',\n",
       " 'THE FEDERAL RESERVE BOARDS : ORG',\n",
       " 'THE HOUSE LABOR SUBCOMMITTEE ON HEALTH AND SAFETY : ORG',\n",
       " 'THE NEW YORK TIMES : ORG',\n",
       " 'THE SENATE BANKING COMMITTEE : ORG',\n",
       " 'THE STATE CHILDRENS HEALTH INSURANCE PROGRAM : ORG',\n",
       " 'THE WASHINGTON POST : ORG',\n",
       " 'THE WHITE HOUSE : ORG',\n",
       " 'TIMES : ORG',\n",
       " 'TREASURY : ORG',\n",
       " 'YEN : MONEY',\n",
       " 'ability',\n",
       " 'abuse',\n",
       " 'accord',\n",
       " 'accuracy',\n",
       " 'achieve',\n",
       " 'administration',\n",
       " 'adopt',\n",
       " 'advantage',\n",
       " 'advocacy',\n",
       " 'afford',\n",
       " 'afternoon',\n",
       " 'against',\n",
       " 'agree',\n",
       " 'ahead',\n",
       " 'aim',\n",
       " 'alive',\n",
       " 'allege',\n",
       " 'allow',\n",
       " 'already',\n",
       " 'also',\n",
       " 'applicant',\n",
       " 'argument',\n",
       " 'assistance',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'attempt',\n",
       " 'auction',\n",
       " 'average',\n",
       " 'await',\n",
       " 'award',\n",
       " 'awareness',\n",
       " 'banking',\n",
       " 'barbiturate',\n",
       " 'be',\n",
       " 'because',\n",
       " 'become',\n",
       " 'begin',\n",
       " 'believe',\n",
       " 'bet',\n",
       " 'bill',\n",
       " 'branch',\n",
       " 'breath',\n",
       " 'briefly',\n",
       " 'broaden',\n",
       " 'business',\n",
       " 'but',\n",
       " 'cadre',\n",
       " 'can',\n",
       " 'capital',\n",
       " 'case',\n",
       " 'cause',\n",
       " 'cd',\n",
       " 'certificate',\n",
       " 'change',\n",
       " 'child',\n",
       " 'children',\n",
       " 'civil',\n",
       " 'clean',\n",
       " 'cocaine',\n",
       " 'codeine',\n",
       " 'come',\n",
       " 'commissioner',\n",
       " 'common',\n",
       " 'company',\n",
       " 'companys',\n",
       " 'competitor',\n",
       " 'comprehensive',\n",
       " 'compromise',\n",
       " 'conclude',\n",
       " 'consultant',\n",
       " 'consumer',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'cover',\n",
       " 'coverage',\n",
       " 'create',\n",
       " 'critical',\n",
       " 'currently',\n",
       " 'damage',\n",
       " 'danger',\n",
       " 'day',\n",
       " 'decline',\n",
       " 'defamation',\n",
       " 'delay',\n",
       " 'denomination',\n",
       " 'deposit',\n",
       " 'deputy',\n",
       " 'directly',\n",
       " 'director',\n",
       " 'disagreement',\n",
       " 'discover',\n",
       " 'dismissal',\n",
       " 'dollar',\n",
       " 'downside',\n",
       " 'drop',\n",
       " 'drug',\n",
       " 'drum',\n",
       " 'ease',\n",
       " 'educate',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effectiveness',\n",
       " 'efficiency',\n",
       " 'effort',\n",
       " 'eligible',\n",
       " 'employee',\n",
       " 'employer',\n",
       " 'employment',\n",
       " 'encourage',\n",
       " 'end',\n",
       " 'endment',\n",
       " 'enormous',\n",
       " 'enrol',\n",
       " 'entry',\n",
       " 'error',\n",
       " 'euro',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'expand',\n",
       " 'experience',\n",
       " 'expire',\n",
       " 'extend',\n",
       " 'extol',\n",
       " 'face',\n",
       " 'fail',\n",
       " 'fall',\n",
       " 'family',\n",
       " 'federal',\n",
       " 'fifth',\n",
       " 'fight',\n",
       " 'final',\n",
       " 'fire',\n",
       " 'first',\n",
       " 'focus',\n",
       " 'follow',\n",
       " 'for',\n",
       " 'force',\n",
       " 'franc',\n",
       " 'fund',\n",
       " 'give',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'grow',\n",
       " 'hand',\n",
       " 'hard',\n",
       " 'havoc',\n",
       " 'head',\n",
       " 'heedlessly',\n",
       " 'help',\n",
       " 'high',\n",
       " 'however',\n",
       " 'human',\n",
       " 'if',\n",
       " 'impair',\n",
       " 'implement',\n",
       " 'important',\n",
       " 'impose',\n",
       " 'improve',\n",
       " 'in',\n",
       " 'include',\n",
       " 'income',\n",
       " 'indecision',\n",
       " 'information',\n",
       " 'initial',\n",
       " 'insurance',\n",
       " 'interest',\n",
       " 'invade',\n",
       " 'invasion',\n",
       " 'issue',\n",
       " 'jeopardize',\n",
       " 'junkie',\n",
       " 'keep',\n",
       " 'kid',\n",
       " 'kit',\n",
       " 'known',\n",
       " 'laboratory',\n",
       " 'large',\n",
       " 'last',\n",
       " 'late',\n",
       " 'lawsuit',\n",
       " 'leadership',\n",
       " 'learn',\n",
       " 'least',\n",
       " 'legal',\n",
       " 'less',\n",
       " 'level',\n",
       " 'libertarian',\n",
       " 'limit',\n",
       " 'loan',\n",
       " 'loss',\n",
       " 'low',\n",
       " 'major',\n",
       " 'make',\n",
       " 'man',\n",
       " 'manage',\n",
       " 'management',\n",
       " 'manager',\n",
       " 'manufacturer',\n",
       " 'many',\n",
       " 'mark',\n",
       " 'market',\n",
       " 'may',\n",
       " 'measure',\n",
       " 'message',\n",
       " 'methadone',\n",
       " 'mid',\n",
       " 'middle',\n",
       " 'misreport',\n",
       " 'modestly',\n",
       " 'month',\n",
       " 'monthly',\n",
       " 'more',\n",
       " 'morphine',\n",
       " 'move',\n",
       " 'national',\n",
       " 'nationwide',\n",
       " 'negotiator',\n",
       " 'new',\n",
       " 'next',\n",
       " 'night',\n",
       " 'nonserious',\n",
       " 'not',\n",
       " 'note',\n",
       " 'number',\n",
       " 'numerous',\n",
       " 'obstacle',\n",
       " 'offense',\n",
       " 'offer',\n",
       " 'official',\n",
       " 'offspring',\n",
       " 'often',\n",
       " 'on',\n",
       " 'opposition',\n",
       " 'overall',\n",
       " 'parent',\n",
       " 'part',\n",
       " 'participant',\n",
       " 'pass',\n",
       " 'passage',\n",
       " 'pause',\n",
       " 'pay',\n",
       " 'pend',\n",
       " 'per',\n",
       " 'percentage',\n",
       " 'perform',\n",
       " 'perhaps',\n",
       " 'period',\n",
       " 'personal',\n",
       " 'phetamine',\n",
       " 'pit',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'plummet',\n",
       " 'point',\n",
       " 'policy',\n",
       " 'political',\n",
       " 'poverty',\n",
       " 'preferable',\n",
       " 'pressure',\n",
       " 'prevent',\n",
       " 'previous',\n",
       " 'privacy',\n",
       " 'private',\n",
       " 'productive',\n",
       " 'productivity',\n",
       " 'professional',\n",
       " 'program',\n",
       " 'proliferation',\n",
       " 'property',\n",
       " 'proposal',\n",
       " 'protect',\n",
       " 'protest',\n",
       " 'provision',\n",
       " 'publish',\n",
       " 'punishment',\n",
       " 'pursue',\n",
       " 'qualify',\n",
       " 'railroad',\n",
       " 'raise',\n",
       " 'rate',\n",
       " 'reauthorize',\n",
       " 'recess',\n",
       " 'recovery',\n",
       " 'reduce',\n",
       " 'reflect',\n",
       " 'reform',\n",
       " 'regulation',\n",
       " 'rehabilitation',\n",
       " 'relation',\n",
       " 'release',\n",
       " 'reluctant',\n",
       " 'remove',\n",
       " 'replacement',\n",
       " 'replenish',\n",
       " 'report',\n",
       " 'require',\n",
       " 'respectively',\n",
       " 'restore',\n",
       " 'restrict',\n",
       " 'restriction',\n",
       " 'result',\n",
       " 'return',\n",
       " 'rigorous',\n",
       " 'risk',\n",
       " 'roughly',\n",
       " 'sale',\n",
       " 'say',\n",
       " 'scope',\n",
       " 'screen',\n",
       " 'second',\n",
       " 'security',\n",
       " 'seek',\n",
       " 'sell',\n",
       " 'send',\n",
       " 'serve',\n",
       " 'service',\n",
       " 'several',\n",
       " 'short',\n",
       " 'sick',\n",
       " 'sign',\n",
       " 'significant',\n",
       " 'since',\n",
       " 'sink',\n",
       " 'slightly',\n",
       " 'small',\n",
       " 'softness',\n",
       " 'somewhat',\n",
       " 'sound',\n",
       " 'spend',\n",
       " 'start',\n",
       " 'starting',\n",
       " 'state',\n",
       " 'statement',\n",
       " 'statistic',\n",
       " 'status',\n",
       " 'step',\n",
       " 'sterling',\n",
       " 'stiff',\n",
       " 'stock',\n",
       " 'stream',\n",
       " 'strong',\n",
       " 'study',\n",
       " 'subject',\n",
       " 'summer',\n",
       " 'supervisor',\n",
       " 'support',\n",
       " 'survey',\n",
       " 'take',\n",
       " 'tell',\n",
       " 'tenth',\n",
       " 'term',\n",
       " 'test',\n",
       " 'testimony',\n",
       " 'testing',\n",
       " 'theory',\n",
       " 'there',\n",
       " 'thought',\n",
       " 'thousand',\n",
       " 'threemonth',\n",
       " 'threshold',\n",
       " 'tighten',\n",
       " 'time',\n",
       " 'to',\n",
       " 'today',\n",
       " 'tone',\n",
       " 'top',\n",
       " 'tough',\n",
       " 'town',\n",
       " 'trace',\n",
       " 'trade',\n",
       " 'trader',\n",
       " 'trim',\n",
       " 'turnover',\n",
       " 'unacceptable',\n",
       " 'unacceptably',\n",
       " 'unchanged',\n",
       " 'under',\n",
       " 'uninsur',\n",
       " 'uninsured',\n",
       " 'valuable',\n",
       " 'vary',\n",
       " 'version',\n",
       " 'virtually',\n",
       " 'virtue',\n",
       " 'voice',\n",
       " 'voluntarily',\n",
       " 'vote',\n",
       " 'wait',\n",
       " 'want',\n",
       " 'watch',\n",
       " 'weak',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'well',\n",
       " 'whose',\n",
       " 'widely',\n",
       " 'widespread',\n",
       " 'win',\n",
       " 'without',\n",
       " 'work',\n",
       " 'worker',\n",
       " 'worry',\n",
       " 'would',\n",
       " 'write',\n",
       " 'year',\n",
       " 'yen',\n",
       " 'yesterday',\n",
       " 'yield']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_object.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 446)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_array.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
